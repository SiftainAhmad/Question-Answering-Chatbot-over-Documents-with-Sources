{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question Answering Chatbot overDocuments_with_Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNQHiqZfCGkr",
    "outputId": "e8fcab31-51c7-4f2b-ead3-2cde37d631ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.4 in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
      "Requirement already satisfied: deeplake in /usr/local/lib/python3.10/dist-packages (3.9.9)\n",
      "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.0.20)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.7.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (8.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.4)\n",
      "Requirement already satisfied: pillow~=10.2.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (10.2.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.34.106)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.1.7)\n",
      "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: humbug>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.2)\n",
      "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.3.3)\n",
      "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake) (2.3.0)\n",
      "Requirement already satisfied: libdeeplake==0.0.129 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.0.129)\n",
      "Requirement already satisfied: aioboto3>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (13.0.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.6.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from libdeeplake==0.0.129->deeplake) (0.3.8)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: aiobotocore[boto3]==2.13.0 in /usr/local/lib/python3.10/dist-packages (from aioboto3>=10.4.0->deeplake) (2.13.0)\n",
      "Requirement already satisfied: aiofiles>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from aioboto3>=10.4.0->deeplake) (23.2.1)\n",
      "Requirement already satisfied: botocore<1.34.107,>=1.34.70 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (1.34.106)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (1.14.1)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (0.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.9.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (0.10.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.4) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.4) (3.0.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (1.7.6.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.70.16)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.107,>=1.34.70->aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (2.8.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.4) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.107,>=1.34.70->aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.4 deeplake openai==0.27.8 tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing newspaper3k for extracting and curating articles from news websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15BW5LkgIv0T",
    "outputId": "10df503e-2727-46c1-bdfe-a009f55c2dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q newspaper3k==0.2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up OPENAI_API_KEY & ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eSFtehNoLP8C"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY']='sk-proj-K74kvdsdfkl;ds;XnXovwvk5OCUFVxIm'\n",
    "\n",
    "os.environ['ACTIVELOOP_TOKEN']='eyJhbGciOiJub2dfsl;kdsaNpZnRhaW4iLCJhcGlfa2Vdsk;ldsk;kltVGxEVUdTUDcwTlNEWGRMbzIzcVVWTjJlIn0.'\n",
    "# Don't try api key, i have changed it ðŸ˜‚ðŸ˜‚ðŸ˜‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imporitng requests for making HTTP requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "11eE6zWCL0Xf"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article #Â https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] #Â where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Embeddings and Storing in Deep Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFEMWNhjMFIA",
    "outputId": "2ae75d3c-5430-4e73-db00-08b9372027a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "WARNING:langchain_community.vectorstores.deeplake:Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "my_activeloop_org_id = \"siftain\" # TODO: use your organization id here\n",
    "my_activeloop_dataset_name = \"langchain_course_qabot_with_source\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the article texts into small chunks using RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mCHYtEdeNATo"
   },
   "outputs": [],
   "source": [
    "# We split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). Each metadata is a dictionary and\n",
    "# we need to use the \"source\" key for the document source so that we can then use the\n",
    "# RetrievalQAWithSourcesChain class which will automatically retrieve the \"source\" item\n",
    "# from the metadata dictionary.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts, all_metadatas = [], []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)\n",
    "        all_metadatas.append({ \"source\": d[\"url\"] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the chunks to Deep Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jt7SGYYcNlsS",
    "outputId": "e9ae8552-c9c3-4dd5-c187-bf7fc8231b32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 49 embeddings in 1 batches of size 49:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://siftain/langchain_course_qabot_with_source', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (49, 1)      str     None   \n",
      " metadata     json      (49, 1)      str     None   \n",
      " embedding  embedding  (49, 1536)  float32   None   \n",
      "    id        text      (49, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bbb10a3e-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb10c0a-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb10ce6-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb10da4-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb10e58-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb10ef8-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb10fac-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1104c-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb110e2-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1118c-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11222-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb112c2-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb113da-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1148e-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11538-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb115d8-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11678-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1172c-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb117ea-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1188a-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1192a-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb119ca-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11a74-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11b1e-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11bc8-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11c7c-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11d3a-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11dee-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11efc-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb11fce-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12082-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1212c-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb121d6-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1228a-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1233e-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb123f2-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb124a6-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1255a-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12604-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb126a4-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1274e-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb127f8-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb1288e-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb129e2-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12a96-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12b2c-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12bc2-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12cb2-2944-11ef-834e-0242ac1c000c',\n",
       " 'bbb12d48-2944-11ef-834e-0242ac1c000c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add all the chunks to the deep lake, along with their metadata\n",
    "db.add_texts(all_texts, all_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the QA Chatbot which also keeps track of the sources using RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcVe2PI_No7b",
    "outputId": "a91b6118-7443-417f-e27b-8041adf81ce1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# we create a RetrievalQAWithSourcesChain chain, which is very similar to a\n",
    "# standard retrieval QA chain but it also keeps track of the sources of the\n",
    "# retrieved documents\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Response along with it's source/sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_KGRTNkOT6I",
    "outputId": "d0e25661-195a-4189-a89a-79f9c44b1d71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " Geoffrey Hinton, known as the \"Godfather of AI,\" has expressed concerns about the potential dangers of AI and left his position at Google to discuss them openly. He has warned about the rapid development of generative AI products and the potential for false information to be spread. Hinton also expressed concerns about the impact of AI on the job market. Other experts, such as Elon Musk, Neil deGrasse Tyson, and Stephen Hawking, have also warned about the risks of AI. \n",
      "\n",
      "Sources:\n",
      "- https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n"
     ]
    }
   ],
   "source": [
    "# We generate a response to a query using the chain. The response object is a dictionary containing\n",
    "# an \"answer\" field with the textual answer to the query, and a \"sources\" field containing a string made\n",
    "# of the concatenation of the metadata[\"source\"] strings of the retrieved documents.\n",
    "d_response = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})\n",
    "\n",
    "print(\"Response:\")\n",
    "print(d_response[\"answer\"])\n",
    "print(\"Sources:\")\n",
    "for source in d_response[\"sources\"].split(\", \"):\n",
    "    print(\"- \" + source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEcsDsp6OkbE"
   },
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
